package edu.uta.cse6331

import org.apache.spark.SparkContext
import org.apache.spark.SparkConf

@SerialVersionUID(123L)
case class M_Matrix(i:Int,j:Int,v:Double) extends Serializable{}

@SerialVersionUID(123L)
case class N_Matrix(j:Int,k:Int,w:Double) extends Serializable{}

object Multiply {
  def main(args: Array[ String ]) {
    val conf = new SparkConf().setAppName("Join")
    val sc = new SparkContext(conf)
    val Mat_m = sc.textFile(args(0)).map( line => { val a = line.split(",")
                                               M_Matrix(a(0).toInt,a(1).toInt,a(2).toDouble) } )
    val Mat_n = sc.textFile(args(1)).map( line => { val a = line.split(",")
                                                N_Matrix(a(0).toInt,a(1).toInt,a(2).toDouble) } )
    val multiply1 = Mat_m.map(Mat_m => (Mat_m.j,(Mat_m.i,Mat_m.v))).join(Mat_n.map(Mat_n => (Mat_n.j,(Mat_n.k,Mat_n.w))))
                        .map{case(j, ((i,v),(k,w))) => ((i,k), v*w)}
    val multiply2 = multiply1.reduceByKey(_+_)
    val final_result = multiply2.collect()
    final_result.foreach(println)
    sc.stop()
  }
}
